{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuseyinAts/Acikhack2023_TrendMiner/blob/main/Osmanlica_ResnetOcr_ipynb_adl%C4%B1_not_defterinin_kopyas%C4%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uToZxZCGrfDM",
        "outputId": "66577531-0604-414f-b7b6-c9c65727ee44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.2 colorlog-6.8.2 optuna-3.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rDxGLTUPzpg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import os\n",
        "import editdistance\n",
        "\n",
        "# OsmanlicaDataset sınıfını burada tanımlayın\n",
        "class OsmanlicaDataset(Dataset):\n",
        "    def __init__(self, image_dir, label_file, transform=None, max_length=100):\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.data = []\n",
        "        self.char_to_idx = {}\n",
        "        self.idx_to_char = {}\n",
        "\n",
        "        with open(label_file, 'r', encoding='utf-8') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        for line in lines:\n",
        "            image_name, label = line.strip().split(',')\n",
        "            self.data.append((image_name, label))\n",
        "\n",
        "            for char in label:\n",
        "                if char not in self.char_to_idx:\n",
        "                    idx = len(self.char_to_idx)\n",
        "                    self.char_to_idx[char] = idx\n",
        "                    self.idx_to_char[idx] = char\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_name, label = self.data[idx]\n",
        "        image_path = os.path.join(self.image_dir, image_name)\n",
        "\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label_encoded = [self.char_to_idx.get(char, 0) for char in label[:self.max_length]]\n",
        "        label_encoded += [0] * (self.max_length - len(label_encoded))  # Padding\n",
        "\n",
        "        return image, torch.tensor(label_encoded, dtype=torch.long)\n",
        "\n",
        "# ResNetGRUAttention model sınıfını burada tanımlayın\n",
        "\n",
        "# FocalLoss sınıfını burada tanımlayın\n",
        "\n",
        "# Diğer yardımcı fonksiyonları tanımlayın (save_model, load_model, predict, vb.)\n",
        "\n",
        "def train(args):\n",
        "    # Eğitim kodunuz burada\n",
        "\n",
        "def main():\n",
        "    # Ana fonksiyon kodunuz burada\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "8T4Zg6gFQShg",
        "outputId": "5fb371e3-4da6-4c85-d573-9f999a87a423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "expected an indented block after function definition on line 56 (<ipython-input-2-8e0d3803b874>, line 59)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-8e0d3803b874>\"\u001b[0;36m, line \u001b[0;32m59\u001b[0m\n\u001b[0;31m    def main():\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uAZWSbzMBxZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/hakantrkgl/ottomantranslate/Dataset/chars\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9m5HJdqA9De",
        "outputId": "d6aa5c68-afe8-4951-f2b5-daf84cdc024d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'chars'...\n",
            "remote: Not Found\n",
            "fatal: repository 'https://github.com/hakantrkgl/ottomantranslate/Dataset/chars/' not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F  # Bu satırı ekleyin\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import os\n",
        "import editdistance\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "# ... (Önceki sınıf ve fonksiyon tanımlamaları aynı kalacak)\n",
        "# OsmanlicaDataset sınıfını burada tanımlayın\n",
        "class OsmanlicaDataset(Dataset):\n",
        "    def __init__(self, image_dir, label_file, transform=None, max_length=100):\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.data = []\n",
        "        self.char_to_idx = {}\n",
        "        self.idx_to_char = {}\n",
        "\n",
        "        with open(label_file, 'r', encoding='utf-8') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        for line in lines:\n",
        "            parts = line.strip().split('\\t')  # Tab ile ayır\n",
        "            if len(parts) >= 2:\n",
        "                image_name = parts[0].split('.')[0]  # Dosya uzantısını kaldır\n",
        "                label = '\\t'.join(parts[1:])  # Etiketin içinde tab varsa\n",
        "                image_path = os.path.join(self.image_dir, f\"{image_name}.png\")\n",
        "                if os.path.exists(image_path):  # Dosyanın var olduğunu kontrol et\n",
        "                    self.data.append((image_name, label))\n",
        "\n",
        "                    for char in label:\n",
        "                        if char not in self.char_to_idx:\n",
        "                            idx = len(self.char_to_idx)\n",
        "                            self.char_to_idx[char] = idx\n",
        "                            self.idx_to_char[idx] = char\n",
        "                else:\n",
        "                    print(f\"Image file not found: {image_path}\")\n",
        "            else:\n",
        "                print(f\"Ignoring invalid line: {line.strip()}\")\n",
        "\n",
        "        print(f\"Loaded {len(self.data)} valid image-label pairs\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_name, label = self.data[idx]\n",
        "        image_path = os.path.join(self.image_dir, f\"{image_name}.png\")\n",
        "\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label_encoded = [self.char_to_idx.get(char, 0) for char in label[:self.max_length]]\n",
        "        label_encoded += [0] * (self.max_length - len(label_encoded))  # Padding\n",
        "\n",
        "        return image, torch.tensor(label_encoded, dtype=torch.long)\n",
        "def save_model(model, path):\n",
        "    torch.save(model.state_dict(), path)\n",
        "    print(f\"Model saved to {path}\")\n",
        "\n",
        "def load_model(model, path, device):\n",
        "    model.load_state_dict(torch.load(path, map_location=device))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def predict(model, image_path, transform, idx_to_char, device, max_length):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "        _, predicted = torch.max(output, 2)\n",
        "\n",
        "    predicted = predicted.squeeze().cpu().numpy()\n",
        "    predicted_text = ''.join([idx_to_char[idx] for idx in predicted if idx in idx_to_char])\n",
        "    return predicted_text[:max_length]  # Maksimum uzunluğa göre kırpma\n",
        "\n",
        "def train(args):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    dataset = OsmanlicaDataset(args.image_dir, args.label_file, transform=transform, max_length=args.max_length)\n",
        "    dataloader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "\n",
        "    model = ResNetGRUAttention(num_classes=args.num_classes, hidden_size=args.hidden_size, max_length=args.max_length)\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = FocalLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=args.learning_rate, weight_decay=1e-5)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.1)\n",
        "\n",
        "    best_cer = float('inf')\n",
        "    patience = 5\n",
        "    no_improve = 0\n",
        "\n",
        "    for epoch in range(args.num_epochs):\n",
        "        train_loss = train_epoch(model, dataloader, criterion, optimizer, device)\n",
        "\n",
        "        val_cer = validate(model, dataloader, dataset.idx_to_char, device)\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{args.num_epochs}], Loss: {train_loss:.4f}, Validation CER: {val_cer:.4f}')\n",
        "\n",
        "        scheduler.step(val_cer)\n",
        "\n",
        "        if val_cer < best_cer:\n",
        "            best_cer = val_cer\n",
        "            no_improve = 0\n",
        "            save_model(model, 'best_model.pth')\n",
        "        else:\n",
        "            no_improve += 1\n",
        "\n",
        "        if no_improve == patience:\n",
        "            print(\"Early stopping!\")\n",
        "            break\n",
        "\n",
        "    return model, dataset  # model ve dataset'i döndür\n",
        "class ResNetGRUAttention(nn.Module):\n",
        "    def __init__(self, num_classes, hidden_size, max_length):\n",
        "        super(ResNetGRUAttention, self).__init__()\n",
        "        self.resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, hidden_size)\n",
        "\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True, bidirectional=True)\n",
        "\n",
        "        self.attention = nn.MultiheadAttention(hidden_size * 2, num_heads=8)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
        "\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.resnet(x)\n",
        "        features = features.unsqueeze(1).repeat(1, self.max_length, 1)\n",
        "\n",
        "        gru_out, _ = self.gru(features)\n",
        "\n",
        "        attn_out, _ = self.attention(gru_out, gru_out, gru_out)\n",
        "\n",
        "        output = self.fc(attn_out)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "def main():\n",
        "    class Args:\n",
        "        def __init__(self):\n",
        "            self.image_dir = \"/content/veri\"\n",
        "            self.label_file = \"/content/veri/label.txt\"\n",
        "            self.batch_size = 32\n",
        "            self.learning_rate = 0.001\n",
        "            self.hidden_size = 256\n",
        "            self.num_epochs = 50\n",
        "            self.num_classes = 1000  # Toplam benzersiz karakter sayısına göre ayarlayın\n",
        "            self.max_length = 100  # Maksimum etiket uzunluğuna göre ayarlayın\n",
        "\n",
        "    args = Args()\n",
        "    print(f\"Image directory: {args.image_dir}\")\n",
        "    print(f\"Label file: {args.label_file}\")\n",
        "\n",
        "    # Modeli eğit\n",
        "    model, dataset = train(args)\n",
        "\n",
        "    # Tahmin için modeli kullan\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2, alpha=None, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        ce_loss = F.cross_entropy(input, target, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
        "\n",
        "        if self.alpha is not None:\n",
        "            alpha_t = self.alpha[target]\n",
        "            focal_loss = alpha_t * focal_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        else:\n",
        "            return focal_loss\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, labels in dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs.view(-1, outputs.size(2)), labels.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def validate(model, dataloader, idx_to_char, device):\n",
        "    model.eval()\n",
        "    total_cer = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 2)\n",
        "\n",
        "            for pred, label in zip(predicted, labels):\n",
        "                pred_text = ''.join([idx_to_char[idx.item()] for idx in pred if idx.item() in idx_to_char])\n",
        "                label_text = ''.join([idx_to_char[idx.item()] for idx in label if idx.item() in idx_to_char])\n",
        "                total_cer += editdistance.eval(pred_text, label_text) / len(label_text)\n",
        "\n",
        "    return total_cer / len(dataloader.dataset)\n",
        "    # Modeli eğit\n",
        "    model, dataset = train(args)\n",
        "\n",
        "    # Tahmin için modeli kullan\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uB91G6zl-PL6",
        "outputId": "b930e98c-e9b7-481d-b2af-0d6c56d888f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image directory: /content/veri\n",
            "Label file: /content/veri/label.txt\n",
            "Using device: cuda\n",
            "Image file not found: /content/veri/label.png\n",
            "Image file not found: /content/veri/1.png\n",
            "Image file not found: /content/veri/3.png\n",
            "Image file not found: /content/veri/23.png\n",
            "Image file not found: /content/veri/24.png\n",
            "Image file not found: /content/veri/25.png\n",
            "Image file not found: /content/veri/26.png\n",
            "Image file not found: /content/veri/27.png\n",
            "Image file not found: /content/veri/28.png\n",
            "Image file not found: /content/veri/29.png\n",
            "Image file not found: /content/veri/30.png\n",
            "Image file not found: /content/veri/31.png\n",
            "Image file not found: /content/veri/32.png\n",
            "Image file not found: /content/veri/33.png\n",
            "Image file not found: /content/veri/34.png\n",
            "Ignoring invalid line: 132.png iyi insanı secdelerden değil\n",
            "Ignoring invalid line: 162.png şüphesiz ki allah adaleti iyiliği ve akrabaya yardım etmeyi emir eder\n",
            "Ignoring invalid line: 174.png bizleri üç aylara kavuşturan rabime şükürler olsun\n",
            "Ignoring invalid line: 191.png emanete ihanet etmemesinden\n",
            "Ignoring invalid line: 238.png sen ne dersen de yine kadındır deliyi de adam eden\n",
            "Ignoring invalid line: 240.png sahibi hürmetine kulu incitme gönül\n",
            "Image file not found: /content/veri/250.png\n",
            "Loaded 228 valid image-label pairs\n",
            "Epoch [1/50], Loss: 3.7438, Validation CER: 0.9441\n",
            "Model saved to best_model.pth\n",
            "Epoch [2/50], Loss: 1.8919, Validation CER: 0.3874\n",
            "Model saved to best_model.pth\n",
            "Epoch [3/50], Loss: 1.4845, Validation CER: 0.3874\n",
            "Epoch [4/50], Loss: 1.4828, Validation CER: 0.4599\n",
            "Epoch [5/50], Loss: 1.4661, Validation CER: 0.3878\n",
            "Epoch [6/50], Loss: 1.3711, Validation CER: 0.3863\n",
            "Model saved to best_model.pth\n",
            "Epoch [7/50], Loss: 1.3739, Validation CER: 0.3842\n",
            "Model saved to best_model.pth\n",
            "Epoch [8/50], Loss: 1.3659, Validation CER: 0.3853\n",
            "Epoch [9/50], Loss: 1.3158, Validation CER: 0.3837\n",
            "Model saved to best_model.pth\n",
            "Epoch [10/50], Loss: 1.2926, Validation CER: 0.3863\n",
            "Epoch [11/50], Loss: 1.3695, Validation CER: 0.3875\n",
            "Epoch [12/50], Loss: 1.3086, Validation CER: 0.3857\n",
            "Epoch [13/50], Loss: 1.4016, Validation CER: 0.3843\n",
            "Epoch [14/50], Loss: 1.3352, Validation CER: 0.3814\n",
            "Model saved to best_model.pth\n",
            "Epoch [15/50], Loss: 1.3088, Validation CER: 0.3802\n",
            "Model saved to best_model.pth\n",
            "Epoch [16/50], Loss: 1.3023, Validation CER: 0.3828\n",
            "Epoch [17/50], Loss: 1.3451, Validation CER: 0.3803\n",
            "Epoch [18/50], Loss: 1.2760, Validation CER: 0.3801\n",
            "Model saved to best_model.pth\n",
            "Epoch [19/50], Loss: 1.2924, Validation CER: 0.3808\n",
            "Epoch [20/50], Loss: 1.2811, Validation CER: 0.3802\n",
            "Epoch [21/50], Loss: 1.2889, Validation CER: 0.3804\n",
            "Epoch [22/50], Loss: 1.3294, Validation CER: 0.3803\n",
            "Epoch [23/50], Loss: 1.2553, Validation CER: 0.3804\n",
            "Early stopping!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import editdistance\n",
        "\n",
        "def load_model(model, path, device):\n",
        "    model.load_state_dict(torch.load(path, map_location=device))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def predict(model, image_path, transform, idx_to_char, device, max_length):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "        _, predicted = torch.max(output, 2)\n",
        "\n",
        "    predicted = predicted.squeeze().cpu().numpy()\n",
        "    predicted_text = ''.join([idx_to_char[idx] for idx in predicted if idx in idx_to_char])\n",
        "    return predicted_text[:max_length]\n",
        "\n",
        "def calculate_accuracy(predictions, ground_truths):\n",
        "    total = len(predictions)\n",
        "    correct = sum(1 for pred, true in zip(predictions, ground_truths) if pred == true)\n",
        "    return correct / total * 100\n",
        "\n",
        "def main():\n",
        "    # Model ve veri seti parametreleri\n",
        "    model_path = 'best_model.pth'\n",
        "    image_dir = \"/content/veri\"\n",
        "    label_file = \"/content/veri/label.txt\"\n",
        "    max_length = 100\n",
        "    num_classes = 1000  # Toplam benzersiz karakter sayısına göre ayarlayın\n",
        "    hidden_size = 256\n",
        "\n",
        "    # Cihazı ayarla\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Dönüşüm işlemlerini tanımla\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Veri setini yükle\n",
        "    dataset = OsmanlicaDataset(image_dir, label_file, transform=None, max_length=max_length)\n",
        "\n",
        "    # Modeli yükle\n",
        "    model = ResNetGRUAttention(num_classes=num_classes, hidden_size=hidden_size, max_length=max_length)\n",
        "    model = load_model(model, model_path, device)\n",
        "    model.to(device)\n",
        "\n",
        "    # Tahminler ve doğruluk hesaplama\n",
        "    predictions = []\n",
        "    ground_truths = []\n",
        "\n",
        "    for idx in range(len(dataset)):\n",
        "        image_name, label = dataset.data[idx]\n",
        "        image_path = os.path.join(image_dir, f\"{image_name}.png\")\n",
        "\n",
        "        prediction = predict(model, image_path, transform, dataset.idx_to_char, device, max_length)\n",
        "        predictions.append(prediction)\n",
        "        ground_truths.append(label)\n",
        "\n",
        "        print(f\"Image: {image_name}, Prediction: {prediction}, Ground Truth: {label}\")\n",
        "\n",
        "    accuracy = calculate_accuracy(predictions, ground_truths)\n",
        "    print(f\"\\nOverall Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biT-lSW-csBY",
        "outputId": "dddd4a24-220f-48ec-c8c5-04c27bfa98a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image file not found: /content/veri/label.png\n",
            "Image file not found: /content/veri/1.png\n",
            "Image file not found: /content/veri/3.png\n",
            "Image file not found: /content/veri/23.png\n",
            "Image file not found: /content/veri/24.png\n",
            "Image file not found: /content/veri/25.png\n",
            "Image file not found: /content/veri/26.png\n",
            "Image file not found: /content/veri/27.png\n",
            "Image file not found: /content/veri/28.png\n",
            "Image file not found: /content/veri/29.png\n",
            "Image file not found: /content/veri/30.png\n",
            "Image file not found: /content/veri/31.png\n",
            "Image file not found: /content/veri/32.png\n",
            "Image file not found: /content/veri/33.png\n",
            "Image file not found: /content/veri/34.png\n",
            "Ignoring invalid line: 132.png iyi insanı secdelerden değil\n",
            "Ignoring invalid line: 162.png şüphesiz ki allah adaleti iyiliği ve akrabaya yardım etmeyi emir eder\n",
            "Ignoring invalid line: 174.png bizleri üç aylara kavuşturan rabime şükürler olsun\n",
            "Ignoring invalid line: 191.png emanete ihanet etmemesinden\n",
            "Ignoring invalid line: 238.png sen ne dersen de yine kadındır deliyi de adam eden\n",
            "Ignoring invalid line: 240.png sahibi hürmetine kulu incitme gönül\n",
            "Image file not found: /content/veri/250.png\n",
            "Loaded 228 valid image-label pairs\n",
            "Image: 2, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: eskimez yazı\n",
            "Image: 4, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: başaran kaç araba var?\n",
            "Image: 5, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: yaşar sağlam masa yapar\n",
            "Image: 6, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: babam sağlam kaynak yapar\n",
            "Image: 7, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: bardak bardak ayran, çanak çanak aş var\n",
            "Image: 8, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: yaramaz hakan taş atar\n",
            "Image: 9, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: kartal kalkar dal sarkar, dal sarkar kartal kalkar\n",
            "Image: 10, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: iri sivri sinek veliyi ısırdı\n",
            "Image: 11, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: işlek işlemeci işleri işleyerek işletmeciye izletti\n",
            "Image: 12, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: girintili çıkıntılı kıyılar, gemiciyi terletti\n",
            "Image: 13, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: titiz ışıl ışığı açtı\n",
            "Image: 14, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: hızlı gemi yılda 2 milyon mil gitti\n",
            "Image: 15, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: eğri direkte kuş durmaz\n",
            "Image: 16, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: serin sularda derin düşüncelere daldı\n",
            "Image: 17, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: tekir kedi tenceredeki eti kendi kendine yedi\n",
            "Image: 18, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: küçük kürekçi uğurlu kürkçüye kürekle vurdu\n",
            "Image: 19, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: bir dilim peynir, iki ekmek yedi\n",
            "Image: 20, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: ince iğne titrek terziyi yıldırdı\n",
            "Image: 21, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: akıntıya kapılan gemi kıyıya sığındı\n",
            "Image: 22, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: ipi biten terzi ipek iplik aldı\n",
            "Image: 35, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: taş atar kaş yarar\n",
            "Image: 36, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: kanayan damar can yakar\n",
            "Image: 37, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: yaşar sağlam masa yapar\n",
            "Image: 38, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: babam kasnak yapmaz\n",
            "Image: 39, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: hakan bayram var, bayrak salla\n",
            "Image: 40, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: dal sarkar, kartal kalkar\n",
            "Image: 41, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: babam çanak satar\n",
            "Image: 42, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: yaramaz hakan taş atar\n",
            "Image: 43, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: parlak çanak, yavaş kaynar\n",
            "Image: 44, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: bardak bardak ayran, çanak çanak aş var\n",
            "Image: 45, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: bal yalayan parmak yalar\n",
            "Image: 46, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: çakal kaçar, kaplan yakalar\n",
            "Image: 47, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: yaşayan parçayla yama yapama\n",
            "Image: 48, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: paşa babam atmaca yakalar\n",
            "Image: 49, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: saçakta çağlayan akmaz\n",
            "Image: 50, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: babacan ayakta ağlamaz\n",
            "Image: 51, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: güzel gören, güzel düşünür\n",
            "Image: 52, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: orhan çok düzgün konuşuyor\n",
            "Image: 53, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: dokuz çocuk, koyundan korkan çobana gülüyor\n",
            "Image: 54, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: tavuk dürüm, kuzu kavurmadan ucuz\n",
            "Image: 55, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: ürkek çocuk gölgede oynar\n",
            "Image: 56, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: çömlekte çorba güzel olur\n",
            "Image: 57, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: tökezleyen kuzu, kurda av olur\n",
            "Image: 58, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: ucuz gömlekten düğme çabuk kopar\n",
            "Image: 59, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: gündüz kömür yakan akşam üşür\n",
            "Image: 60, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: kuru odun, kömürden çabuk tutuşur\n",
            "Image: 61, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: öğretmenler, özel örneklerdir\n",
            "Image: 62, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: uzman öğretmen özel okulda görev yapar\n",
            "Image: 63, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: utangaç uğraşa uğraşa uzun uzun urgan satar\n",
            "Image: 64, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: dereden tekne geçmez\n",
            "Image: 65, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: peltek emre kereste keser\n",
            "Image: 66, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: yedek tekerlek nerede?\n",
            "Image: 67, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: emel evde serçe besler\n",
            "Image: 68, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: tenbel bebek dedemden ekmek bekler\n",
            "Image: 69, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: evde bekleme, emre hemen gelmez\n",
            "Image: 70, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: dedem serçeye ekmek atar\n",
            "Image: 71, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: esen tepede menekşe açmaztene keden baca az çeker\n",
            "Image: 73, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: teneke kapta kelebek beslenmez\n",
            "Image: 74, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: baba eve deterjan al\n",
            "Image: 75, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: eşek dar semere, serçe bayat ekmeğe gelmez\n",
            "Image: 76, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: tepeden bere takan, evde terler\n",
            "Image: 77, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: patlak tekerler, sağlam eşekten yeğdir\n",
            "Image: 78, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: tembel kaplan serçe avlamaz\n",
            "Image: 79, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: çayda şeker, bezelyede salça sever\n",
            "Image: 80, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: umut özel görev yapar\n",
            "Image: 81, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: horoz uzun uzun öter\n",
            "Image: 82, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: ne kadar yaşadığımız değil. nasıl yaşadığımız önemli.\n",
            "Image: 83, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: her insan huzur verir kimi gelince kimi gidince\n",
            "Image: 84, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: ah masumiyet! biz büyüdükçe sen tükendin içimizde.\n",
            "Image: 85, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: derdi dünya olanın dünya kadar derdi olur\n",
            "Image: 86, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: parası olan pazardan imanı olan mezardan korkmaz.\n",
            "Image: 87, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: yazıyor ... yazıyor ... kiramen katibin melekleri yaptığın her şeyi tek tek yazıyooooooor ....\n",
            "Image: 88, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: hayatta bazı engellerin bir hikmeti vardır\n",
            "Image: 89, Prediction: aaaa       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: eğer hikmetiyle bir kapıyı kapatırsa rahmetiyle başkasını açar.\n",
            "Image: 90, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: besmeleyi divana kadar .\n",
            "Image: 91, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: şeytanın artistliği\n",
            "Image: 92, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: aşka varınca kanadı kim arar\n",
            "Image: 93, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: aşka uçmazsan kanat neye yarar\n",
            "Image: 94, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: aşka uçarsan kanatların yarar\n",
            "Image: 95, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: o gün ne mal faide verir , ne  de evlat ! ancak allaha selim (sağlam) bir kalbe gelen müstesna\n",
            "Image: 96, Prediction: aaaa       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: geceniz mübarek ola, hayırlara fet ola, şerler def ola, bu duaya amin diyen iki cihanda aziz ola.\n",
            "Image: 97, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: yo ben 28 yıldır kullanıyorum hiç bağımlılık yapmadı.\n",
            "Image: 98, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: yalnız bu ilaçlar bağımlılık yapar.\n",
            "Image: 99, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: nerden anladın\n",
            "Image: 100, Prediction: aaaaa     eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: buraya çöp döken eşşektir\n",
            "Image: 101, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: insan bazen kendini de okumalı hatta yargılamalı\n",
            "Image: 102, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: en çok gürültü boş tenekelerden çıkar\n",
            "Image: 103, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: pis boğaz ile boş boğaz,\n",
            "Image: 104, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: yaran istersen kuran yeter.\n",
            "Image: 105, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: dost istersen allah(c c) yeter.\n",
            "Image: 106, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: düşman istersen nefis yeter.\n",
            "Image: 107, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: mal istersen kanaat yeter.\n",
            "Image: 108, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: nasihat istersen ölüm yeter.\n",
            "Image: 109, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: mutluluk aramakla bulunacak şey değildir. onu inşa edin.\n",
            "Image: 110, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: osmanlı ordu marşı ey şanlı ordu, ey şanlı asker haydi gazanfer, uman safter bir elde kalkan, bir elde hançer serhadde doğru ey şanlı asker. deryada olsa herşey muzaffer dillerde tekbir, allah ekber allah ekber, allah ekber ordumuz olsun daim muzaffer.\n",
            "Image: 111, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: insanlardan bir şey isteme. zira verse minnet, vermese zillet, sen allahtan iste. zira verse nimet, vermese hikmet.\n",
            "Image: 112, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: ferman büyük yerden: “tiz zamanda osmanlıca öğrenile! kimse ceddinin kitaplarına , kabir taşlarına boş boş bakmaya!”\n",
            "Image: 113, Prediction: aaaa       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: iki yüzlü insanların dilinde tat kalbinde ise fesat gizlidir.\n",
            "Image: 114, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: önemli olan, içinden çıktığın sütü ak bırakmaktır.\n",
            "Image: 115, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: sütten çıkınca bütün kaşıklar aktır.\n",
            "Image: 116, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: okuyun, çünkü mürekkebin akmadığı yerde kan akıyor.\n",
            "Image: 117, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: patates bile bazı insanlarda onurlu hiç olmazsa kızarıyor\n",
            "Image: 118, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: gördükleri ile karar verenler göremediklerine yem olurlar.\n",
            "Image: 119, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: evinde huzur varsa yediğin soğan olsun.\n",
            "Image: 120, Prediction: aaaaaa   eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: ilim öğrenmek kadın erkek her Müslümana farzdır.\n",
            "Image: 121, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: en mutlu \"son\" hafta sonudur\n",
            "Image: 122, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: gönül yaptığı işte değilse bedenin çektiği eziyettir .\n",
            "Image: 123, Prediction: aaaaa     eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: en iyi nasihat iyi örnek olmaktır.\n",
            "Image: 124, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: alim ile konuşursan alırsın mertebe cahil ile konuşursan dönersin merkebe\n",
            "Image: 125, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: aşk, allaha değilse... can yakar...\n",
            "Image: 126, Prediction: aaaaa     eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: bulutlar ağlamasa yeşillikler nasıl güler?\n",
            "Image: 127, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: hayvandan insana dönen yoktur ama insandan hayvana dönen çoktur\n",
            "Image: 128, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: Namaz sancıma ilaç yanık yerime merhem\n",
            "Image: 129, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: aklım kalbime iman nedir diye sordu.\n",
            "Image: 130, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: kalbim ise eğilip aklımın kulağına eğilerek imân edeptir. dedi.\n",
            "Image: 131, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: bizi aldatan bizden değildir.\n",
            "Image: 133, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: doğru sözünden ve emanete ihanet etmemesinden tanırsın\n",
            "Image: 134, Prediction: aaaaa     eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: kurşuna dizilirken bile diktatöre karşı çıkıp duruşunu bozmayacak nice insan var!\n",
            "Image: 135, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: kadınların akıllı adam aramalarına anlam veremiyorum zaten deli edeceksin neyin peşindesin\n",
            "Image: 136, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: kavuşmak istersen mevlaya , vur tekmeyi dünyaya.\n",
            "Image: 137, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: gülmek her zaman mutlu olmak için değildir .\n",
            "Image: 138, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: bazen öyle gülmeler vardır ki en büyük acıları gizlemek içindir .\n",
            "Image: 139, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: ya rabi! helalini helal\n",
            "Image: 140, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: tertemiz bir ömür geçirmeği bize nasip eyle!\n",
            "Image: 141, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: ümitsizlik yok\n",
            "Image: 142, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: gün gelir, gül de açar, bülbül de öter.\n",
            "Image: 143, Prediction: aaaaa     eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: sezai karakoç\n",
            "Image: 144, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: yapılan bir günah ile övünmek, o günahı yapmaktan daha kötüdür.\n",
            "Image: 145, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: yaptığı bir iyilikten dolayı kalbi sürurla dolan\n",
            "Image: 146, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: bilmeyerek işlediği bir günah\n",
            "Image: 147, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: sebebiylede gönlü burkulan bir kimse iyi bir mümin demektir.\n",
            "Image: 148, Prediction: aaaa       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: allahım, ömrümün kalan kısmını, geçen kısmından hayırlı eyle.\n",
            "Image: 149, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: kimle gezdiginize kimle arkadaşlık ettiğinize dikkat edin\n",
            "Image: 150, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: çünkü bülbül güle\n",
            "Image: 151, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: karga çöplüğe götürür.\n",
            "Image: 152, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: yalancı dünyaya aldanma ya hu Bu dernek dağılır divan eğlenmez\n",
            "Image: 153, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: iki kapılı bir viranedir bu bunda konan göçer konuk eğlenmez\n",
            "Image: 154, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: bakma bunun karasına ağına gönül verme bostanına bağına\n",
            "Image: 155, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: gönül verme bostanına bağına\n",
            "Image: 156, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: benzer hemen çocuk oyuncağına\n",
            "Image: 157, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: burada aklı olan insan eğlenmez\n",
            "Image: 158, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: kuşak farkı\n",
            "Image: 159, Prediction: aaaaaa   eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: müziğin sesini kısmaya üşendiğin ezanı şimdi dört gözle bekliyorsun\n",
            "Image: 160, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: boş zaman yoktur boşa geçen zaman vardır\n",
            "Image: 161, Prediction: aaaa       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: aşk, sen başkasın ile başlar, hepiniz aynısınız ile biter.\n",
            "Image: 163, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: daha bir baska geliyor kulağıma ezan\n",
            "Image: 164, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: rahmet ayı gelince huzurlu oluyor insan\n",
            "Image: 165, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: melekler uçuşurken esir kalıyor şeytan\n",
            "Image: 166, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: hoş geldin ramazan\n",
            "Image: 167, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: ümitsizlik yok gün gelir gül de açar bülbül de öter\n",
            "Image: 168, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: yalnızlıktan şikayet etme sakın\n",
            "Image: 169, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: hiç bir günah cehennemde yanmaya değmez\n",
            "Image: 170, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: yapılan bir günah ile övünmek o günahı yapmaktan daha kötüdür\n",
            "Image: 171, Prediction: aaaaaaa eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: zamanım yoğrulur gamla birleşir sabah akşamla ılık kanım damla damla akar gider dosta doğru\n",
            "Image: 172, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: al işte yine sabah olmuş ben uyurken günaydın bari\n",
            "Image: 173, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: güzelliğin on para etmez, şu bendeki aşk olmasa.\n",
            "Image: 175, Prediction: aaaaa     eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: heybetini hazreti hamzadan isimini hazret- ömerden alan vatan sevdasıyla tutuşup iman aşkıyla yanan yiğit bu gece senin gecen\n",
            "Image: 176, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: dünyayı kendinize efendi edinmeyinki o da sizi kendisine köle etmesin\n",
            "Image: 177, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: vicdanını değil aklını yitirmişlere deli diyor insanlar\n",
            "Image: 178, Prediction: aaaaaaa eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: deniz dalgazsız olmaz güzel sevdasız olmaz yâri güzel olanın başı belası olmaz\n",
            "Image: 179, Prediction: aaaaaa   eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: haydi git mini mini maşallah kavuşursuz allah\n",
            "Image: 180, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: geleydin bir çay içmeye sen çayı dökerdin ben içimi\n",
            "Image: 181, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: türk ordusu bir asır önce dünyanın en güçlü ordularını çanakkale de dize getirdi\n",
            "Image: 182, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: yıl önce dünyanın en güçlü donanmalarına geçit vermeyerek çanak kale geçilmez\n",
            "Image: 183, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: sözünü dünya tarihine yazdıran kahraman şehitlerimizi ve gazilerimi rahmet ve minnetle yad ediyoruz\n",
            "Image: 184, Prediction: aaaa       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: hayırlı feyizli bereketli sağlıklı\n",
            "Image: 185, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: evdeki hesabımız bile çarşıya uymuyorken ahiret hesabımızın vay haline..\n",
            "Image: 186, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: kahveye yüklenen anlam\n",
            "Image: 187, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: misafire ikram edilen kahve ve beraberindeki su bir mesaj taşıyordu\n",
            "Image: 188, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: alırsa tok suyu alırsa aç olduğu anlaşılıyordu ev sahibi misafirin\n",
            "Image: 189, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: aç olduğunu anlarsa nazikçe sofrayı kurar misafirin karnını doyururdu\n",
            "Image: 190, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: eğer misafir ilk olarak eline kahveyi alırsa tok\n",
            "Image: 192, Prediction: aaaaaaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: kötü insanların hayatına girmesi seni üzmek için değil iyi ve kötüyü ayırt edebilmen içindir\n",
            "Image: 193, Prediction: aaaaaa   eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: terk ettiğiniz yerde yokluğunuz belli olmuyor sa doğru yoldasınız demektir fevzi çelebi\n",
            "Image: 194, Prediction: aaaa       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: sabır dikendir tevekkül edersen çiçek açar\n",
            "Image: 195, Prediction: aaaa       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: aşık veysel in dediği gibi adam olmayana düşman bile olma\n",
            "Image: 196, Prediction: aaaa      eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: öyle uzaktan seyir etme\n",
            "Image: 197, Prediction: aaaaaa   eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: adına hayran olduğum yar buyur gel ömrüme ömrüm ömrün olsun\n",
            "Image: 198, Prediction: aaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: dua ettiğinizde çok isteyin\n",
            "Image: 199, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: çünkü vereceği hiçbir şey allaha ağır gelmez\n",
            "Image: 200, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: insanı ateş değil kendi gafleti yakar\n",
            "Image: 201, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: herkesde kusur görür kendine kör bakar\n",
            "Image: 202, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: neye nasıl bakarsan o da sana öyle bakar\n",
            "Image: 203, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: mevlana hazretleri\n",
            "Image: 204, Prediction: aaaa       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: nurlu sabahlar\n",
            "Image: 205, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: en tatlı sabahlar sabah namazı ile başlar\n",
            "Image: 206, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: bahşedilen aklı kullan, her yolun yolcusu olma .\n",
            "Image: 207, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: cam kırıkları gibidir bazen kelimeler\n",
            "Image: 208, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: düne tövbe bugüne secde yarına dua yakışır\n",
            "Image: 209, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: allah ne güzel sevgili der\n",
            "Image: 210, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: misafir gele cekmiş gibi evini ölüm gelecekmiş gibi kalbini temiz tut\n",
            "Image: 211, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: en tatlı sabahlar sabah namazı ile başlar\n",
            "Image: 212, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: dünyayı ahirete götüremeyeceğine göre\n",
            "Image: 213, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: gönlü yarada olanın anlı secde de olur\n",
            "Image: 214, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: kızgınlığım geçer de kırgınlıklarıma çare bulamadım\n",
            "Image: 215, Prediction: aaaa      eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: yolumuz gazadır sonu şehadet\n",
            "Image: 216, Prediction: aaaaa     eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: dinimiz ister sıdk ile hizmet anamız vatandır babamız millet vatanı mamur eyle ya rabbi\n",
            "Image: 217, Prediction: aaaaa     eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: milleti mesrur eyle ya rabbi\n",
            "Image: 218, Prediction: aaaaa     eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: minareler süngü kübbeler miğfer camiler kışlamız müminler asker\n",
            "Image: 219, Prediction: aaaaa     eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: bu ilahi ordu dünyamı bekler allah ekber allah ekber\n",
            "Image: 220, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: hakkı hakkıya gitmiş hakkıdan hakkını istemiş\n",
            "Image: 221, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: sen nasılsın diye bir sor kötüysemde iyi olurum\n",
            "Image: 222, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: nice elbiseler gördüm içinde insan yok.\n",
            "Image: 223, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: nice insanlar gördüm üzerinde elbise yok\n",
            "Image: 224, Prediction: aaaa       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: sular hep aktı geçti kurudu vakti geçti,\n",
            "Image: 225, Prediction: aaa          eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: nice han nice sultan tahtı bıraktı geçti,\n",
            "Image: 226, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: dünya bir penceredir, er gelen baktı geçti\n",
            "Image: 227, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: üç günlük dünya için gayret üstüne gayret ebedi bir dünya için gayret yok hayret\n",
            "Image: 228, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: ömür dediğin nedir ki bir ezan bir sala\n",
            "Image: 229, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: insanları olgunlaştıran yaşı değil yaşadıklarıdır\n",
            "Image: 230, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: yarın yaparım, yarın yaparım deme bugün de dünün\n",
            "Image: 231, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: yarınıydı ne yapabildin\n",
            "Image: 232, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: büyük tükenmez bir kuvvet ne çok bitmez bir bereket olduğunu anlamak\n",
            "Image: 233, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: nebat ve ağaç ve otların ipek gibi yumuşak kök ve\n",
            "Image: 234, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: insanı ateş değiş kendi gafleti yakar\n",
            "Image: 235, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: herkeste kusur görür kendisine kor bakar\n",
            "Image: 236, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: neye nasıl bakarsan o da sana öyle bakar\n",
            "Image: 237, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: kadınmış derler adamı deli eden\n",
            "Image: 239, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: dokunur gayretine karışma hikmetine sahibi hürmetine kulu incitme gönül\n",
            "Image: 241, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: insan bu dünyaya yalnız güzel yaşamak için ve rahat ve safa ile ömür geçirmek için gelmemiştir\n",
            "Image: 242, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: herkes bir şeçim yapar\n",
            "Image: 243, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: ve seçtiği yaşamın bedelini öder\n",
            "Image: 244, Prediction: aaaa        eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: osmanlı tarihini latin harfleriyle\n",
            "Image: 245, Prediction: aaa          eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: öğrenmek mümkün değildir\n",
            "Image: 246, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: aşkı kalem yazmaz ki, kitaplarda bulasın\n",
            "Image: 247, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: en büyük mezar insanın içine gömdükleridir\n",
            "Image: 248, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: herkes birini bulur ama birbirini bulmak çok az insana nasip olur\n",
            "Image: 249, Prediction: aaa         eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee, Ground Truth: insanı bir kere küstürdün mü artık kalbini onarmak ne zordur\n",
            "\n",
            "Overall Accuracy: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import os\n",
        "import editdistance\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class ArabicDataset(Dataset):\n",
        "    def __init__(self, image_dir, label_file, transform=None, max_length=100):\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.data = []\n",
        "        self.char_to_idx = {' ': 0}\n",
        "        self.idx_to_char = {0: ' '}\n",
        "\n",
        "        arabic_chars = 'ابتثجحخدذرزسشصضطظعغفقكلمنهوي'\n",
        "        for char in arabic_chars:\n",
        "            if char not in self.char_to_idx:\n",
        "                idx = len(self.char_to_idx)\n",
        "                self.char_to_idx[char] = idx\n",
        "                self.idx_to_char[idx] = char\n",
        "\n",
        "        with open(label_file, 'r', encoding='utf-8') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        for line in lines:\n",
        "            parts = line.strip().split('\\t')\n",
        "            if len(parts) >= 2:\n",
        "                image_name = parts[0].split('.')[0]\n",
        "                label = parts[1]\n",
        "                image_path = os.path.join(self.image_dir, f\"{image_name}.png\")\n",
        "                if os.path.exists(image_path):\n",
        "                    self.data.append((image_name, label))\n",
        "                else:\n",
        "                    print(f\"Image file not found: {image_path}\")\n",
        "            else:\n",
        "                print(f\"Ignoring invalid line: {line.strip()}\")\n",
        "\n",
        "        print(f\"Loaded {len(self.data)} valid image-label pairs\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_name, label = self.data[idx]\n",
        "        image_path = os.path.join(self.image_dir, f\"{image_name}.png\")\n",
        "\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label_encoded = [self.char_to_idx.get(char, 0) for char in label[:self.max_length]]\n",
        "        label_encoded += [0] * (self.max_length - len(label_encoded))\n",
        "\n",
        "        return image, torch.tensor(label_encoded, dtype=torch.long)\n",
        "\n",
        "class ResNetBiGRUAttention(nn.Module):\n",
        "    def __init__(self, num_classes, hidden_size, max_length):\n",
        "        super(ResNetBiGRUAttention, self).__init__()\n",
        "        self.resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, hidden_size)\n",
        "\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True, bidirectional=True)\n",
        "\n",
        "        self.attention = nn.MultiheadAttention(hidden_size * 2, num_heads=8)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
        "\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.resnet(x)\n",
        "        features = features.unsqueeze(1).repeat(1, self.max_length, 1)\n",
        "\n",
        "        gru_out, _ = self.gru(features)\n",
        "\n",
        "        attn_out, _ = self.attention(gru_out, gru_out, gru_out)\n",
        "\n",
        "        output = self.fc(attn_out)\n",
        "\n",
        "        return output\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2, alpha=None, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        ce_loss = F.cross_entropy(input, target, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
        "\n",
        "        if self.alpha is not None:\n",
        "            alpha_t = self.alpha[target]\n",
        "            focal_loss = alpha_t * focal_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        else:\n",
        "            return focal_loss\n",
        "\n",
        "def arabic_transform():\n",
        "    return transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomRotation(5),\n",
        "        transforms.RandomAffine(degrees=0, translate=(0.05, 0.05), scale=(0.95, 1.05)),\n",
        "        transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, labels in dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs.view(-1, outputs.size(2)), labels.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def validate(model, dataloader, idx_to_char, device):\n",
        "    model.eval()\n",
        "    total_cer = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 2)\n",
        "\n",
        "            for pred, label in zip(predicted, labels):\n",
        "                pred_text = ''.join([idx_to_char[idx.item()] for idx in pred if idx.item() in idx_to_char])\n",
        "                label_text = ''.join([idx_to_char[idx.item()] for idx in label if idx.item() in idx_to_char])\n",
        "                total_cer += editdistance.eval(pred_text, label_text) / len(label_text)\n",
        "\n",
        "    return total_cer / len(dataloader.dataset)\n",
        "\n",
        "def save_model(model, path):\n",
        "    torch.save(model.state_dict(), path)\n",
        "    print(f\"Model saved to {path}\")\n",
        "\n",
        "def load_model(model, path, device):\n",
        "    model.load_state_dict(torch.load(path, map_location=device))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def predict(model, image_path, transform, idx_to_char, device, max_length):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "        _, predicted = torch.max(output, 2)\n",
        "\n",
        "    predicted = predicted.squeeze().cpu().numpy()\n",
        "    predicted_text = ''.join([idx_to_char[idx] for idx in predicted if idx in idx_to_char])\n",
        "    return predicted_text[:max_length]\n",
        "\n",
        "def plot_training_progress(train_losses, val_cers):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(val_cers, label='Validation CER')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('CER')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def main():\n",
        "    # Parametreler\n",
        "    image_dir = \"/content/veri\"\n",
        "    label_file = \"/content/veri/label.txt\"\n",
        "    batch_size = 32\n",
        "    learning_rate = 0.001\n",
        "    hidden_size = 256\n",
        "    num_epochs = 50\n",
        "    num_classes = len(ArabicDataset(image_dir, label_file).char_to_idx)\n",
        "    max_length = 100\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Veri yükleme ve dönüştürme\n",
        "    transform = arabic_transform()\n",
        "    dataset = ArabicDataset(image_dir, label_file, transform=transform, max_length=max_length)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "\n",
        "    # Model oluşturma\n",
        "    model = ResNetBiGRUAttention(num_classes=num_classes, hidden_size=hidden_size, max_length=max_length)\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = FocalLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.1)\n",
        "\n",
        "    # Eğitim\n",
        "    best_cer = float('inf')\n",
        "    train_losses = []\n",
        "    val_cers = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = train_epoch(model, dataloader, criterion, optimizer, device)\n",
        "        val_cer = validate(model, dataloader, dataset.idx_to_char, device)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_cers.append(val_cer)\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Validation CER: {val_cer:.4f}')\n",
        "\n",
        "        scheduler.step(val_cer)\n",
        "\n",
        "        if val_cer < best_cer:\n",
        "            best_cer = val_cer\n",
        "            save_model(model, 'best_arabic_model.pth')\n",
        "\n",
        "    plot_training_progress(train_losses, val_cers)\n",
        "\n",
        "    # Test\n",
        "    test_image_path = \"/content/test\"\n",
        "    best_model = load_model(model, 'best_arabic_model.pth', device)\n",
        "    prediction = predict(best_model, test_image_path, transform, dataset.idx_to_char, device, max_length)\n",
        "    print(f\"Prediction: {prediction}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tsfX9HnSeB9B",
        "outputId": "3e547ad6-8ce2-499c-cc76-cca9a5edc8a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image file not found: /content/veri/label.png\n",
            "Image file not found: /content/veri/1.png\n",
            "Image file not found: /content/veri/3.png\n",
            "Image file not found: /content/veri/23.png\n",
            "Image file not found: /content/veri/24.png\n",
            "Image file not found: /content/veri/25.png\n",
            "Image file not found: /content/veri/26.png\n",
            "Image file not found: /content/veri/27.png\n",
            "Image file not found: /content/veri/28.png\n",
            "Image file not found: /content/veri/29.png\n",
            "Image file not found: /content/veri/30.png\n",
            "Image file not found: /content/veri/31.png\n",
            "Image file not found: /content/veri/32.png\n",
            "Image file not found: /content/veri/33.png\n",
            "Image file not found: /content/veri/34.png\n",
            "Ignoring invalid line: 132.png iyi insanı secdelerden değil\n",
            "Ignoring invalid line: 162.png şüphesiz ki allah adaleti iyiliği ve akrabaya yardım etmeyi emir eder\n",
            "Ignoring invalid line: 174.png bizleri üç aylara kavuşturan rabime şükürler olsun\n",
            "Ignoring invalid line: 191.png emanete ihanet etmemesinden\n",
            "Ignoring invalid line: 238.png sen ne dersen de yine kadındır deliyi de adam eden\n",
            "Ignoring invalid line: 240.png sahibi hürmetine kulu incitme gönül\n",
            "Image file not found: /content/veri/250.png\n",
            "Loaded 228 valid image-label pairs\n",
            "Using device: cuda\n",
            "Image file not found: /content/veri/label.png\n",
            "Image file not found: /content/veri/1.png\n",
            "Image file not found: /content/veri/3.png\n",
            "Image file not found: /content/veri/23.png\n",
            "Image file not found: /content/veri/24.png\n",
            "Image file not found: /content/veri/25.png\n",
            "Image file not found: /content/veri/26.png\n",
            "Image file not found: /content/veri/27.png\n",
            "Image file not found: /content/veri/28.png\n",
            "Image file not found: /content/veri/29.png\n",
            "Image file not found: /content/veri/30.png\n",
            "Image file not found: /content/veri/31.png\n",
            "Image file not found: /content/veri/32.png\n",
            "Image file not found: /content/veri/33.png\n",
            "Image file not found: /content/veri/34.png\n",
            "Ignoring invalid line: 132.png iyi insanı secdelerden değil\n",
            "Ignoring invalid line: 162.png şüphesiz ki allah adaleti iyiliği ve akrabaya yardım etmeyi emir eder\n",
            "Ignoring invalid line: 174.png bizleri üç aylara kavuşturan rabime şükürler olsun\n",
            "Ignoring invalid line: 191.png emanete ihanet etmemesinden\n",
            "Ignoring invalid line: 238.png sen ne dersen de yine kadındır deliyi de adam eden\n",
            "Ignoring invalid line: 240.png sahibi hürmetine kulu incitme gönül\n",
            "Image file not found: /content/veri/250.png\n",
            "Loaded 228 valid image-label pairs\n",
            "Epoch [1/50], Loss: 0.4342, Validation CER: 0.0000\n",
            "Model saved to best_arabic_model.pth\n",
            "Epoch [2/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [3/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [4/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [5/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [6/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [7/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [8/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [9/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [10/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [11/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [12/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [13/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [14/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [15/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [16/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [17/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [18/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [19/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [20/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [21/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [22/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [23/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [24/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [25/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [26/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [27/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [28/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [29/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [30/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [31/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [32/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [33/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [34/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [35/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [36/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [37/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [38/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [39/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [40/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [41/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [42/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [43/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [44/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [45/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [46/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [47/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [48/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [49/50], Loss: 0.0000, Validation CER: 0.0000\n",
            "Epoch [50/50], Loss: 0.0000, Validation CER: 0.0000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "IsADirectoryError",
          "evalue": "[Errno 21] Is a directory: '/content/test'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-5308eb2fd7e5>\u001b[0m in \u001b[0;36m<cell line: 246>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-5308eb2fd7e5>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0mtest_image_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/test\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'best_arabic_model.pth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_image_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx_to_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Prediction: {prediction}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-5308eb2fd7e5>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, image_path, transform, idx_to_char, device, max_length)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_to_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3227\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3228\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/content/test'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Arapça karakterler\n",
        "arabic_chars = 'ابتثجحخدذرزسشصضطظعغفقكلمنهوي'\n",
        "char_to_idx = {char: idx for idx, char in enumerate(arabic_chars, start=1)}\n",
        "char_to_idx['PAD'] = 0  # Padding için\n",
        "idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
        "\n",
        "class KHATTDataset(Dataset):\n",
        "    def __init__(self, root_dir, split='train', transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.split = split\n",
        "        self.transform = transform\n",
        "        self.data = []\n",
        "\n",
        "        split_file = os.path.join(root_dir, f'{split}.txt')\n",
        "        with open(split_file, 'r', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                img_path, label = line.strip().split('\\t')\n",
        "                self.data.append((img_path, label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.data[idx]\n",
        "        img = Image.open(os.path.join(self.root_dir, 'Images', img_path)).convert('L')\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        label_encoded = [char_to_idx.get(c, 0) for c in label]\n",
        "        return img, torch.LongTensor(label_encoded)\n",
        "\n",
        "class ArabicOCRModel(nn.Module):\n",
        "    def __init__(self, num_chars):\n",
        "        super(ArabicOCRModel, self).__init__()\n",
        "        self.cnn = models.resnet18(pretrained=True)\n",
        "        self.cnn.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.cnn.fc = nn.Linear(self.cnn.fc.in_features, 256)\n",
        "        self.lstm = nn.LSTM(256, 128, bidirectional=True, batch_first=True)\n",
        "        self.fc = nn.Linear(256, num_chars)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        features = self.cnn(x)\n",
        "        features = features.view(batch_size, 256, -1).permute(0, 2, 1)\n",
        "        lstm_out, _ = self.lstm(features)\n",
        "        output = self.fc(lstm_out)\n",
        "        return output\n",
        "\n",
        "def train(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, labels in tqdm(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "\n",
        "        input_lengths = torch.full((outputs.size(0),), outputs.size(1), dtype=torch.long)\n",
        "        target_lengths = torch.sum(labels != 0, dim=1)\n",
        "\n",
        "        loss = criterion(outputs.permute(1, 0, 2), labels, input_lengths, target_lengths)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "def evaluate(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(val_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "\n",
        "            input_lengths = torch.full((outputs.size(0),), outputs.size(1), dtype=torch.long)\n",
        "            target_lengths = torch.sum(labels != 0, dim=1)\n",
        "\n",
        "            loss = criterion(outputs.permute(1, 0, 2), labels, input_lengths, target_lengths)\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(val_loader)\n",
        "\n",
        "def main():\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Veri dönüşümleri\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485], std=[0.229])\n",
        "    ])\n",
        "\n",
        "    # Veri yükleyicileri\n",
        "    train_dataset = KHATTDataset(root_dir='path/to/KHATT', split='train', transform=transform)\n",
        "    val_dataset = KHATTDataset(root_dir='path/to/KHATT', split='val', transform=transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "    # Model oluşturma\n",
        "    model = ArabicOCRModel(num_chars=len(char_to_idx)).to(device)\n",
        "\n",
        "    # Loss ve optimizer\n",
        "    criterion = nn.CTCLoss(blank=0, zero_infinity=True)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Eğitim döngüsü\n",
        "    num_epochs = 50\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = train(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
        "\n",
        "        # Model kaydetme\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            torch.save(model.state_dict(), f'arabic_ocr_model_epoch_{epoch+1}.pth')\n",
        "\n",
        "    print(\"Eğitim tamamlandı!\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "Rw-Re4vZhlyg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}